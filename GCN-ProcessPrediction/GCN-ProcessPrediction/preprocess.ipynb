{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-13T05:59:36.706770Z",
     "start_time": "2024-07-13T05:59:28.717692900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import encode_map\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def process(df, att_encode_map):\n",
    "    df_filter = df.loc[:, [\"case\", \"activity\", \"timestamp\"]]\n",
    "    new_names = {\"case\": \"CaseID\", \"activity\": \"ActivityID\", \"timestamp\":\"CompleteTimestamp\"}\n",
    "    df_filter = df_filter.rename(columns=new_names)\n",
    "    # 将时间戳列转换为日期时间对象\n",
    "    df_filter['CompleteTimestamp'] = pd.to_datetime(df_filter['CompleteTimestamp'])\n",
    "    # 格式化时间戳列为所需的字符串格式\n",
    "    df_filter['CompleteTimestamp'] = df_filter['CompleteTimestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df_filter[\"ActivityID\"] = df_filter[\"ActivityID\"].apply(lambda e: att_encode_map.get(str(e), -1))\n",
    "    return df_filter\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T05:59:36.760351Z",
     "start_time": "2024-07-13T05:59:36.714779200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing fold: 100%|██████████| 3/3 [00:13<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_eventlog = [\n",
    "    'helpdesk',\n",
    "    # 'bpi13_problems',\n",
    "    # 'bpi13_closed_problems',\n",
    "    # 'bpi12_all_complete',\n",
    "    # 'bpi12w_complete',\n",
    "    # 'bpic2017_o',\n",
    "    # 'bpi12_work_all',\n",
    "    # 'receipt',\n",
    "    # 'bpic2020',\n",
    "    # 'bpi13_incidents',\n",
    "]\n",
    "\n",
    "for event_name in list_eventlog:\n",
    "    for f in tqdm(range(3), desc=\"Processing fold\"):\n",
    "        df_train = pd.read_csv(\"raw_dir/three_fold_data/\" + event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"_train.csv\",\n",
    "                               sep=',',\n",
    "                               header=0, index_col=False)\n",
    "        df_test = pd.read_csv(\"raw_dir/three_fold_data/\" + event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"_test.csv\",\n",
    "                              sep=',',\n",
    "                              header=0, index_col=False)\n",
    "        np.random.seed(133)\n",
    "        grouped = df_train.groupby('case')\n",
    "        new_order = np.random.permutation(list(grouped.groups.keys()))\n",
    "        new_groups = [grouped.get_group(key) for key in new_order]\n",
    "        log_shuffled = pd.concat(new_groups)\n",
    "        log_shuffled.index = range(len(log_shuffled))\n",
    "        train, valid = train_test_split(log_shuffled, test_size=0.2, shuffle=False)\n",
    "        all_df = pd.concat([train, valid, df_test], ignore_index=True)\n",
    "        att_encode_map = encode_map(set(all_df[\"activity\"].values))\n",
    "        train_processed = process(train, att_encode_map)\n",
    "        valid_processed = process(valid, att_encode_map)\n",
    "        test_processed = process(df_test, att_encode_map)\n",
    "        all_df_processed = pd.concat([train_processed, valid_processed, test_processed], ignore_index=True)\n",
    "\n",
    "        train_index = list(range(len(train_processed)))\n",
    "        valid_index = list(range(len(train_processed), len(train_processed) + len(valid_processed)))\n",
    "        test_index = list(range(len(train_processed) + len(valid_processed), len(all_df_processed)))\n",
    "        if not os.path.exists(\"raw_dir/\" + event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f)):\n",
    "            os.makedirs(\"raw_dir/\"+ event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f))\n",
    "        all_df_processed.to_csv(\"raw_dir/\"+ event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"/\" + event_name + \"_all.csv\", index=False)\n",
    "        with open(\"raw_dir/\"+ event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"/\" + 'train' + '_' + \"index\" + \".npy\", 'wb') as file:\n",
    "            pickle.dump(train_index, file)\n",
    "        with open(\"raw_dir/\"+ event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"/\" + 'valid' + '_' + \"index\" + \".npy\", 'wb') as file:\n",
    "            pickle.dump(valid_index, file)\n",
    "        with open(\"raw_dir/\"+ event_name + \"/\" + event_name + \"_kfoldcv_\" + str(f) + \"/\" + 'test' + '_' + \"index\" + \".npy\", 'wb') as file:\n",
    "            pickle.dump(test_index, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T05:59:50.541544300Z",
     "start_time": "2024-07-13T05:59:36.766350900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T05:59:50.541544300Z",
     "start_time": "2024-07-13T05:59:50.437977100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T05:59:50.705677Z",
     "start_time": "2024-07-13T05:59:50.486517800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-tuduipytorch-py",
   "language": "python",
   "display_name": "Python [conda env:tuduipytorch] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
